{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp2SmUqsx8GT"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_train = load_dataset(\n",
        "    'cifar10',\n",
        "    split='train'\n",
        "    # The 'cifar10' loader doesn't support 'ignore_verifications'. Removing it.\n",
        ")\n",
        "\n",
        "dataset_train"
      ],
      "metadata": {
        "id": "NPuzI9XuychR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = load_dataset(\n",
        "    'cifar10',\n",
        "    split='test', # training dataset\n",
        "    # ignore_verifications=True  # set to True if seeing splits Error\n",
        ")\n",
        "\n",
        "dataset_test"
      ],
      "metadata": {
        "id": "ci6alFOd0cUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(dataset_train['label']))\n",
        "labels = dataset_train.features['label']\n",
        "num_classes, labels"
      ],
      "metadata": {
        "id": "I-HJYrie0qSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X=dataset_train[10]['img'])"
      ],
      "metadata": {
        "id": "zHOnvnOx2bbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[0]['label'],labels.names[dataset_train[10]['label']]"
      ],
      "metadata": {
        "id": "9SIx4zZK3qDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor\n",
        "model_id = 'google/vit-base-patch16-224-in21k'\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(\n",
        "    model_id\n",
        ")"
      ],
      "metadata": {
        "id": "p-hAtadj4Jxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor"
      ],
      "metadata": {
        "id": "ucM4H4fj4V6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = feature_extractor(\n",
        "    dataset_train[0]['img'],\n",
        "    return_tensors='pt'\n",
        ")\n",
        "example"
      ],
      "metadata": {
        "id": "6vLBhRZ54aFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example['pixel_values'].shape"
      ],
      "metadata": {
        "id": "TCIUucG34jjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "faMWY7xd4l8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(batch):\n",
        "    inputs = feature_extractor(\n",
        "        batch['img'],\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    inputs['label'] = batch['label']\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "XvLGbDj540i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_train = dataset_train.with_transform(preprocess)\n",
        "prepared_test = dataset_test.with_transform(preprocess)"
      ],
      "metadata": {
        "id": "qN683rmF482Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
        "        'labels': torch.tensor([x['label'] for x in batch])\n",
        "    }"
      ],
      "metadata": {
        "id": "YGGUpdLg5Dy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate"
      ],
      "metadata": {
        "id": "4Kkoo8aj5xyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np\n",
        "from evaluate import load # import load instead of load_metric\n",
        "metric = load(\"accuracy\") # use load instead of load_metric\n",
        "def compute_metrics(p):\n",
        "    return metric.compute(\n",
        "        predictions=np.argmax(p.predictions, axis=1),\n",
        "        references=p.label_ids\n",
        "    )"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "i4hJahY06FL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=\"./cifar\",\n",
        "  per_device_train_batch_size=16,\n",
        "  evaluation_strategy=\"steps\",\n",
        "  num_train_epochs=4,\n",
        "  save_steps=100,\n",
        "  eval_steps=100,\n",
        "  logging_steps=10,\n",
        "  learning_rate=2e-4,\n",
        "  save_total_limit=2,\n",
        "  remove_unused_columns=False,\n",
        "  push_to_hub=False,\n",
        "  load_best_model_at_end=True,\n",
        ")"
      ],
      "metadata": {
        "id": "ft-HAOZd6b8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTForImageClassification\n",
        "\n",
        "labels = dataset_train.features['label'].names\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=len(labels)\n",
        ")"
      ],
      "metadata": {
        "id": "mq7k1ZyD6dAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "ujH_sS-h6iSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=prepared_train,\n",
        "    eval_dataset=prepared_test,\n",
        "    tokenizer=feature_extractor,\n",
        ")"
      ],
      "metadata": {
        "id": "JU5-r83S65MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate(prepared_test)\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "id": "8roGfSlg7Q0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = dataset_test[\"img\"][10].resize((200,200))\n",
        "image"
      ],
      "metadata": {
        "id": "xe8d4t2W7UF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_label = dataset_test[\"label\"][10]\n",
        "\n",
        "labels = dataset_test.features['label']\n",
        "actual_label, labels.names[actual_label]"
      ],
      "metadata": {
        "id": "ZyJExRgr7twp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
        "model_name_or_path = 'LaCarnevali/vit-cifar10'\n",
        "model_finetuned = ViTForImageClassification.from_pretrained(model_name_or_path)\n",
        "feature_extractor_finetuned = ViTFeatureExtractor.from_pretrained(model_name_or_path)"
      ],
      "metadata": {
        "id": "TggQwXii8bL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = feature_extractor_finetuned(image, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model_finetuned(**inputs).logits"
      ],
      "metadata": {
        "id": "b9yu8cqb8gsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label = logits.argmax(-1).item()\n",
        "labels = dataset_test.features['label']\n",
        "labels.names[predicted_label]"
      ],
      "metadata": {
        "id": "02TbiL-c8m52"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}